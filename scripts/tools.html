

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tools &mdash; GQCNN 0.1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="GQCNN 0.1.0 documentation" href="../index.html"/>
        <link rel="next" title="Analysis" href="../api/analysis.html"/>
        <link rel="prev" title="Examples" href="examples.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> GQCNN
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../info/info.html">What are GQ-CNNs?</a></li>
</ul>
<p class="caption"><span class="caption-text">Installation Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/install.html">Dependencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/install.html#python-installation">Python Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/install.html#ros-installation">ROS Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/install.html#quick-start-guide">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/install.html#documentation">Documentation</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../data/data.html">Download Link</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/data.html#datasets">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/data.html#models">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/data.html#license">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/benchmarks.html">Dex-Net 2.0</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorial.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorial.html#training">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorial.html#grasp-planning">Grasp Planning</a></li>
</ul>
<p class="caption"><span class="caption-text">Documentation for Scripts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-training">training.py</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#author">Author</a></li>
<li class="toctree-l3"><a class="reference internal" href="#yaml-configuration-file-parameters">YAML Configuration File Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-fine-tuning-configuration">Training/Fine-Tuning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#analysis-configuration">Analysis Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-visualize_predictions">visualize_predictions.py</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Author</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">YAML Configuration File Parameters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-plot_training_losses">plot_training_losses.py</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">Author</a></li>
<li class="toctree-l3"><a class="reference internal" href="#required-parameters">Required Parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/analysis.html">Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/gqcnn.html">GQCNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/grasping.html">Grasping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/policy.html">Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/visualization.html">Visualization</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">GQCNN</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Tools</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/scripts/tools.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tools">
<h1>Tools<a class="headerlink" href="#tools" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-training">
<span id="training-py"></span><h2>training.py<a class="headerlink" href="#module-training" title="Permalink to this headline">¶</a></h2>
<p>Script with examples for:
1) Training Grasp Quality Neural Networks(GQ-CNN&#8217;s) using Stochastic Gradient Descent
2) Predicting probability of grasp success from images in batches using a pre-trained GQ-CNN model
3) Fine-tuning a GQ-CNN model
4) Analyzing a GQC-NN model</p>
<div class="section" id="author">
<h3>Author<a class="headerlink" href="#author" title="Permalink to this headline">¶</a></h3>
<p>Vishal Satish</p>
</div>
<div class="section" id="yaml-configuration-file-parameters">
<h3>YAML Configuration File Parameters<a class="headerlink" href="#yaml-configuration-file-parameters" title="Permalink to this headline">¶</a></h3>
<div class="section" id="training-fine-tuning-configuration">
<h4>Training/Fine-Tuning Configuration<a class="headerlink" href="#training-fine-tuning-configuration" title="Permalink to this headline">¶</a></h4>
<dl class="docutils">
<dt>dataset_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the location of the dataset to use for training ex. /path/to/your/dataset</dd>
<dt>output_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the location to save the trained model, which will be saved as model_XXXXX where XXXXX will
be a randomly generated string of characters. Note: if the debug flag is on this model name will stay the same so the same model directory
will continuosuly be over-written. If debug is off, a new name and thus directrory will be generated every time.</dd>
<dt>model_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>if the fine-tune flag is on this is the model that will be loaded for training ex. /path/to/pre-trained/model</dd>
<dt>train_batch_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of datapoints to process during each iteration of training</dd>
<dt>val_batch_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of datapoints to process during each iteration of validation</dd>
<dt>num_epochs</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of epoches to train for</dd>
<dt>eval_frequency</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the validation error will be calculated after this many iterations</dd>
<dt>save_frequency</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the model will be saved after this many iterations</dd>
<dt>vis_frequency</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>if the visualization flag is turned on visualization will occur after this many iterations</dd>
<dt>log_frequency</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>training metrics will be logged after this many iterations</dd>
<dt>show_filters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to show network filters during training</dd>
<dt>queue_capacity</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>total capacity of data prefetch queue</dd>
<dt>queue_sleep</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>how long to sleep between data prefetches</dd>
<dt>data_split_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>how to split up the data into training and validation, options are 1) image wise-randomly shuffle and split images 2) stable_pose_wise-randomly shuffle all valid stable
poses of objects and then split so that all datapoints of a certain stable pose are entirely in either training or validation 3) object_wise-randomly shuffle all objects and split into training and validation
so that all datapoints of a certain object are entirely in training or validation</dd>
<dt>train_pct</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>percentage of datapoints to use for training</dd>
<dt>val_pct</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>percentage of datapoints to use for validation</dd>
<dt>total_pct</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>percentage of total datapoints to use</dd>
<dt>eval_total_train_error</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to evaluate the total training error and save it at the end of optimization</dd>
<dt>loss</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the loss function to use, currently supported options are 1) l2-l2 loss 2) sparse-sparse softmax cross entropy with logits loss</dd>
<dt>optimizer</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the optimizer to use, currently supported options are 1) momentum 2) adam 3) rmsprop</dd>
<dt>train_l2_regularizer</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd><dl class="first last docutils">
<dt>factor to multiple summed regularizers by before adding to loss:</dt>
<dd>loss = loss + train_l2_regularizer * regularizers</dd>
</dl>
</dd>
<dt>base_lr</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>base learning rate</dd>
<dt>decay_step_multiplier</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>number of times to go through entire training datapoints before stepping down decay rate</dd>
<dt>decay_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>decay rate during optimization</dd>
<dt>momentum_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>momentume rate if using momentum optimizer</dd>
<dt>max_training_examples_per_load</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>maximum number of training datapoints to use in each batch</dd>
<dt>fine_tune</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not fine-tuning</dd>
<dt>update_fc_only</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to only update the first fully-connected layer</dd>
<dt>update_conv0_only</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to only update the first convolution layer</dd>
<dt>reinit_pc1</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to re-initialize the weights for the first pose layer</dd>
<dt>reinit_fc3</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to re-initialize the weights for the third fully-connected layer</dd>
<dt>reinit_fc4</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to re-initialize the weights for the fourth fully-connected layer</dd>
<dt>reinit_fc5</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) used during fine-tuning to indicate whether or not to re-initialize the weights for the fifth fully-connected layer</dd>
<dt>image_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the type of the input image datapoints, please refer to the README for the dataset for the possible options</dd>
<dt>training_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd><ol class="first last arabic simple">
<li>classification or 2) regression</li>
</ol>
</dd>
<dt>preproc_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the data pre-processing mode for use during regression, options are: 1) normalized 2) none</dd>
<dt>input_data_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the format to use for the input pose data, please refer to the README for the dataset for the possible options</dd>
<dt>num_tensor_channels</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of image channels</dd>
<dt>num_random_files</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the sub-sample size when calculating dataset metrics such as image_mean, pose_mean, image_std, pose_std</dd>
<dt>target_metric_name</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the name of the target metric to use when training, please refer to the README for the dataset for the possible options</dd>
<dt>metric_thresh</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the threshold to use when converting the grasp probability metric predicted by the network into a binary metric</dd>
<dt>multiplicative_denoising</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to apply multiplicative denoising to the images</dd>
<dt>gamma_shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>gamma shape to use for multiplicative_denoising</dd>
<dt>symmetrize</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to symmetrize images by randomly rotating and reflecting</dd>
<dt>morphological</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to apply morphological filters to images</dd>
<dt>morph_open_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>open rate for morphological filter</dd>
<dt>morph_poisson_mean</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>poisson mean to use for morphological filter</dd>
<dt>image_dropout</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to randomly dropout regions of the images for robustness</dd>
<dt>image_dropout_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>rate at which specific images are chosen to have regions dropped from them</dd>
<dt>dropout_poisson_mean</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>poisson mean to use when dropping regions from image</dd>
<dt>dropout_radius_shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>shape of dropout radius</dd>
<dt>dropout_radius_scale</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>scale fo dropout radius</dd>
<dt>gradient_dropout</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to drop out a region around the areas of the images with high gradient</dd>
<dt>gradient_dropout_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>rate at which specific images are chosen to have gradients dropped out</dd>
<dt>gradient_dropout_sigma</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>sigma value for gradient dropout</dd>
<dt>gradient_dropout_shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>shape of gradient dropout filter</dd>
<dt>gradient_dropout_scale</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>scale of gradient dropout filter</dd>
<dt>gaussian_process_denoising</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to add correlated gaussian noise to images</dd>
<dt>gaussian_process_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>rate at which specific images are chosen to have added correlated gaussian noise</dd>
<dt>gaussian_process_scaling_factor</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>scaling factor to use for added correlated gaussian noise</dd>
<dt>gaussian_process_sigma</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>sigma to use for added correlated gaussian noise</dd>
<dt>border_distortion</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to randomly dropout regions of the image borders for robustness</dd>
<dt>border_grad_sigma</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>sigma for gaussian gradient magnitude calculation</dd>
<dt>border_grad_thresh</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>threshold for finding high gradient pixels in the image</dd>
<dt>border_poisson_mean</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>poisson mean for calculating the number of dropout regions</dd>
<dt>border_radius_shape</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>shape of radius of filter for border dropouts</dd>
<dt>border_radius_scale</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>scale of radius of filter for border dropouts</dd>
<dt>background_denoising</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to apply background denoising to images</dd>
<dt>background_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>rate at which specific images are chosen to have background denoising applied</dd>
<dt>background_min_depth</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>minimum depth in meters for background denoising</dd>
<dt>background_max_depth</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>maximum depth in meters for background denoising</dd>
<dt>debug</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to use debug mode, in debug mode the same model name is used for saving between multiple
optimizations and the model directory is thus overwritten. Also the number of datapoints used for training is limited by the size
of the following debug_num_file parameter</dd>
<dt>debug_num_files</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the max number of files from the dataset to use for training and validation</dd>
<dt>gqcnn_config/im_height</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the height of the input image data in pixels</dd>
<dt>gqcnn_config/im_width</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the width of the input image data in pixels</dd>
<dt>gqcnn_config/im_channels</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of channels in the input images</dd>
<dt>gqcnn_config/input_data_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the type of the input image datapoints, please refer to the README for the dataset for the possible options, NOTE: if the network is being fine-tuned
then this parameter must match what was used for training as otherwise the pose tensor dimensions will not match</dd>
<dt>gqcnn_config/batch_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the batch size to use for prediction from this network, in training using the SGDOptimizer this will be overridden by the val_batch_size parameter
in the training config</dd>
<dt>gqcnn_config/architecture</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">dict</span><dd>this section outlines the architecture of the GQ-CNN. Convolutional layers are denoted by the notation convX_Y where X is the group that the layer belongs to
and Y is the individual layer id. Ex. conv1_1 and conv1_2 are the first and second convolutional layers of the first group of convolutional layers. Layers that process pose
data are denoted by pcY where Y is the layer id. Fully-connected layers are denoted by fcY where Y is the layer id. Underneath each layer are its vairous properties such as filter dimensions,
number of filters, pooling size, normalization type and output_size. Please see the actual yaml file for an example architecture definition.</dd>
<dt>radius</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the network normalization radius</dd>
<dt>alpha</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the network normalization alpha</dd>
<dt>beta</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the network normalization beta</dd>
<dt>bias</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the network normalization bias</dd>
</dl>
</div>
<div class="section" id="analysis-configuration">
<h4>Analysis Configuration<a class="headerlink" href="#analysis-configuration" title="Permalink to this headline">¶</a></h4>
<dl class="docutils">
<dt>model_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the outer directory containing the models to be analyzed, ex. if the path to one of the models to be analyzed is
/home/user/models/grasp_quality/model_XXXX then the model_dir is /home/user/models/grasp_quality/</dd>
<dt>output_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the output directory to save the output figures and/or filters from analysis, ex. /home/users/analyses/gqcnn_training_performance</dd>
<dt>out_rate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the frequency with which to use dataset files for analyses, ex. if 1 then every single file is used, if 2 then every other file is used</dd>
<dt>font_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the font size to use in figures</dd>
<dt>dpi</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the dpi to use when plotting figures</dd>
<dt>models</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">dict</span><dd>a dictionary of models to analyze along with their analyzation parameters. The following documentation assumes we have
a sample moduled named model_XXXX and describes the various model parameters</dd>
<dt>models/model_XXXX/tag</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the tag to be prepended before the curve titles</dd>
<dt>models/model_XXXX/type</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the type of model, options are: 1) gqcnn 2) rf 3) svm</dd>
<dt>models/model_XXXX/split_type</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>how the data was split into training and validation, options are 1) image wise-randomly shuffle and split images 2) stable_pose_wise-randomly shuffle all valid stable
poses of objects and then split so that all datapoints of a certain stable pose are entirely in either training or validation 3) object_wise-randomly shuffle all objects and split into training and validation
so that all datapoints of a certain object are entirely in training or validation. This will determine which sets of indices are read in from the model directory</dd>
<dt>models/model_XXXX/vis_conv</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>flag (0 or 1) whether or not to display and save convolution filters from the model directory</dd>
</dl>
</div>
</div>
</div>
<div class="section" id="module-visualize_predictions">
<span id="visualize-predictions-py"></span><h2>visualize_predictions.py<a class="headerlink" href="#module-visualize_predictions" title="Permalink to this headline">¶</a></h2>
<p>Script for visualizing the predictions made by a given Grasp Quality Neural Network(GQ-CNN) model
on a given dataset. Allows for the visualization of true-positives, true-negatives, false-positives, and
false negatives.</p>
<div class="section" id="id1">
<h3>Author<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Vishal Satish</p>
</div>
<div class="section" id="id2">
<h3>YAML Configuration File Parameters<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>dataset_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the path to the dataset to use for visualization, ex. /path/to/dataset</dd>
<dt>image_mode</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the type of the input image datapoints, please refer to the README for the dataset for the possible options</dd>
<dt>data_format</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the format to use for the input pose data, please refer to the README for the dataset for the possible options</dd>
<dt>metric_name</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the name of the target metric to use when training, please refer to the README for the dataset for the possible options</dd>
<dt>metric_thresh</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the threshold to use when converting the target metric into a binary metric</dd>
<dt>gripper_width_m</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>the robot gripper width in meters (used only for visualization)</dd>
<dt>model_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the path to the GQ-CNN model to use for predicting from the specified dataset, ex. /path/to/your/model</dd>
<dt>datapoint_type</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>which datapoints to visualize, options: 1) false_positive 2) false_negative 3) true_positive 4) true_negative</dd>
<dt>display_image_type</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>the type of image to display the grasps on during visualization, options: 1) depth 2) color 3) grayscale 4) rgbd 5) gd 6) segmask</dd>
<dt>font_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the font size to use for visualization</dd>
<dt>samples_per_object</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>the number of predictions to display per object</dd>
</dl>
</div>
</div>
<div class="section" id="module-plot_training_losses">
<span id="plot-training-losses-py"></span><h2>plot_training_losses.py<a class="headerlink" href="#module-plot_training_losses" title="Permalink to this headline">¶</a></h2>
<p>Script to plot the various errors saved during training.</p>
<div class="section" id="id3">
<h3>Author<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Jeff Mahler</p>
</div>
<div class="section" id="required-parameters">
<h3>Required Parameters<a class="headerlink" href="#required-parameters" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>model_dir</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>Command line argument, the path to the model whose errors are to plotted. All plots and other metrics will
be saved to this directory.</dd>
</dl>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../api/analysis.html" class="btn btn-neutral float-right" title="Analysis" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="examples.html" class="btn btn-neutral" title="Examples" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Vishal Satish, Jeff Mahler.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>